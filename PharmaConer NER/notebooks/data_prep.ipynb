{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/victor/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm')\n",
    "stops = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(x):\n",
    "    try:\n",
    "        return nlp(x)[0].pos_\n",
    "    except:\n",
    "        'DUMMY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [08:35<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "document_count = 0\n",
    "documents = []\n",
    "sentences = []\n",
    "words = []\n",
    "tags = []\n",
    "poss = []\n",
    "\n",
    "for file in tqdm(os.listdir('../raw_data/train/subtrack1/')):\n",
    "    \n",
    "    if '.txt' in file:\n",
    "\n",
    "        annfile = file.replace('.txt','.ann')\n",
    "        #document_count += 1\n",
    "        document = file.replace('.txt','')\n",
    "        \n",
    "        text = open(os.path.join('../raw_data/train/subtrack1/',file),'r',encoding='utf-8').readlines()\n",
    "        annotations = open(os.path.join('../raw_data/train/subtrack1/',annfile),'r',encoding='utf-8').readlines()\n",
    "        annotation_dict = {}\n",
    "        for annotation in annotations:\n",
    "            annotation = annotation.replace('\\n','')\n",
    "            annotation = annotation.replace('\\t',' ')\n",
    "            if annotation[0] == 'T':\n",
    "                tag = annotation.split()[1]\n",
    "                n1 = int(annotation.split()[2])\n",
    "                n2 = int(annotation.split()[3])\n",
    "                val = \" \".join(annotation.split()[4:])\n",
    "                id1 = n1\n",
    "                for v in val.split():\n",
    "                    #print (v, id1,id1+len(v))\n",
    "                    annotation_dict[(id1,id1+len(v))] = tag\n",
    "                    id1 = id1 + len(v) + 1\n",
    "        \n",
    "        sentence_count = 0\n",
    "        n1 = 0\n",
    "        n2 = 0\n",
    "        lines = \"\".join(text)\n",
    "        for c in lines:\n",
    "            n2 += 1\n",
    "            if c == ' ':\n",
    "                if lines[n2-2] in [',','.','?','%',';','-','+','&']: \n",
    "                    tag = annotation_dict.get((n1,n2-2),\"OTHER\")\n",
    "                    word = lines[n1:n2-2]\n",
    "                    #print ((n1,n2-2), word, tag)\n",
    "                else:\n",
    "                    tag = annotation_dict.get((n1,n2-1),\"OTHER\")\n",
    "                    word = lines[n1:n2-1]\n",
    "                if len(word) > 0 and word not in stops:\n",
    "                    documents.append(document)\n",
    "                    sentences.append(sentence_count)\n",
    "                    words.append(word.lower())\n",
    "                    poss.append(get_pos(word))\n",
    "                    if len(annotation_dict) > 0:\n",
    "                        tags.append(tag)\n",
    "                    else:\n",
    "                        tags.append('NULL')\n",
    "                    #print ((n1,n2-1), word, tag)\n",
    "                n1 = n2\n",
    "            if c == '\\n':\n",
    "                sentence_count += 1\n",
    "\n",
    "subtask1_train = pd.DataFrame()\n",
    "subtask1_train['document'] = documents\n",
    "subtask1_train['sentence'] = sentences\n",
    "subtask1_train['word'] = words\n",
    "subtask1_train['tag'] = tags\n",
    "subtask1_train['pos'] = poss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOUN     52251\n",
       "ADJ      23696\n",
       "VERB     13541\n",
       "NUM       6019\n",
       "ADV       3502\n",
       "PROPN     3451\n",
       "ADP       2011\n",
       "PUNCT     1984\n",
       "PRON      1791\n",
       "DET       1713\n",
       "AUX        776\n",
       "CONJ       257\n",
       "SCONJ      234\n",
       "INTJ       170\n",
       "SYM         32\n",
       "SPACE        4\n",
       "Name: pos, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtask1_train.pos.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OTHER               93482\n",
      "NULL                14188\n",
      "NORMALIZABLES        2174\n",
      "PROTEINAS            1501\n",
      "UNCLEAR                68\n",
      "NO_NORMALIZABLES       19\n",
      "Name: tag, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (subtask1_train.tag.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "33\n",
      "359\n"
     ]
    }
   ],
   "source": [
    "print (subtask1_train.document.nunique())\n",
    "print (subtask1_train.groupby(['document'])['sentence'].nunique().max())\n",
    "print (subtask1_train.groupby(['document','sentence'])['word'].nunique().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [04:07<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "document_count = 0\n",
    "documents = []\n",
    "sentences = []\n",
    "words = []\n",
    "tags = []\n",
    "n1s = []\n",
    "n2s = []\n",
    "poss = []\n",
    "for file in tqdm(os.listdir('../raw_data/dev/subtrack1/')):\n",
    "    \n",
    "    if '.txt' in file:\n",
    "\n",
    "        annfile = file.replace('.txt','.ann')\n",
    "        #document_count += 1\n",
    "        document = file.replace('.txt','')\n",
    "        \n",
    "        text = open(os.path.join('../raw_data/dev/subtrack1/',file),'r',encoding='utf-8').readlines()\n",
    "        annotations = open(os.path.join('../raw_data/dev/subtrack1/',annfile),'r',encoding='utf-8').readlines()\n",
    "        annotation_dict = {}\n",
    "        for annotation in annotations:\n",
    "            annotation = annotation.replace('\\n','')\n",
    "            annotation = annotation.replace('\\t',' ')\n",
    "            if annotation[0] == 'T':\n",
    "                tag = annotation.split()[1]\n",
    "                n1 = int(annotation.split()[2])\n",
    "                n2 = int(annotation.split()[3])\n",
    "                val = \" \".join(annotation.split()[4:])\n",
    "                id1 = n1\n",
    "                for v in val.split():\n",
    "                    #print (v, id1,id1+len(v))\n",
    "                    annotation_dict[(id1,id1+len(v))] = tag\n",
    "                    id1 = id1 + len(v) + 1\n",
    "        \n",
    "        sentence_count = 0\n",
    "        n1 = 0\n",
    "        n2 = 0\n",
    "        lines = \"\".join(text)\n",
    "        for c in lines:\n",
    "            n2 += 1\n",
    "            if c == ' ':\n",
    "                if lines[n2-2] in [',','.','?','%',';','-','+','&']: \n",
    "                    tag = annotation_dict.get((n1,n2-2),\"OTHER\")\n",
    "                    word = lines[n1:n2-2]\n",
    "                    #print ((n1,n2-2), word, tag)\n",
    "                else:\n",
    "                    tag = annotation_dict.get((n1,n2-1),\"OTHER\")\n",
    "                    word = lines[n1:n2-1]\n",
    "                if len(word) > 0 and word not in stops:\n",
    "                    documents.append(document)\n",
    "                    sentences.append(sentence_count)\n",
    "                    words.append(word.lower())\n",
    "                    poss.append(get_pos(word))\n",
    "                    if len(annotation_dict) > 0:\n",
    "                        tags.append(tag)\n",
    "                    else:\n",
    "                        tags.append('NULL')\n",
    "                    #print ((n1,n2-1), word, tag)\n",
    "                    n1s.append(n1)\n",
    "                    if lines[n2-2] in [',','.','?','%',';','-','+','&']:\n",
    "                        n2s.append(n2-2)\n",
    "                    else:\n",
    "                        n2s.append(n2-1)\n",
    "                n1 = n2\n",
    "            if c == '\\n':\n",
    "                sentence_count += 1\n",
    "\n",
    "subtask1_dev = pd.DataFrame()\n",
    "subtask1_dev['document'] = documents\n",
    "subtask1_dev['sentence'] = sentences\n",
    "subtask1_dev['n1'] = n1s\n",
    "subtask1_dev['n2'] = n2s\n",
    "subtask1_dev['word'] = words\n",
    "subtask1_dev['tag'] = tags\n",
    "subtask1_dev['pos'] = poss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOUN     25032\n",
       "ADJ      11334\n",
       "VERB      6632\n",
       "NUM       2863\n",
       "ADV       1656\n",
       "PROPN     1535\n",
       "ADP       1067\n",
       "PUNCT      933\n",
       "DET        894\n",
       "PRON       863\n",
       "AUX        343\n",
       "CONJ       139\n",
       "INTJ       104\n",
       "SCONJ      103\n",
       "SYM         15\n",
       "SPACE        1\n",
       "Name: pos, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtask1_dev.pos.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OTHER               47127\n",
       "NULL                 4463\n",
       "NORMALIZABLES        1048\n",
       "PROTEINAS             836\n",
       "UNCLEAR                27\n",
       "NO_NORMALIZABLES       13\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtask1_dev.tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "22\n",
      "264\n"
     ]
    }
   ],
   "source": [
    "print (subtask1_dev.document.nunique())\n",
    "print (subtask1_dev.groupby(['document'])['sentence'].nunique().max())\n",
    "print (subtask1_dev.groupby(['document','sentence'])['word'].nunique().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtask1_train.to_csv('../data/subtask1_train.csv',index=False)\n",
    "subtask1_dev.to_csv('../data/subtask1_dev.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3751/3751 [3:00:26<00:00,  1.06s/it]    \n"
     ]
    }
   ],
   "source": [
    "document_count = 0\n",
    "documents = []\n",
    "sentences = []\n",
    "words = []\n",
    "tags = []\n",
    "n1s = []\n",
    "n2s = []\n",
    "poss = []\n",
    "for file in tqdm(os.listdir('../raw_data/background/')):\n",
    "    \n",
    "    if '.txt' in file:\n",
    "\n",
    "        annfile = file.replace('.txt','.ann')\n",
    "        #document_count += 1\n",
    "        document = file.replace('.txt','')\n",
    "        \n",
    "        text = open(os.path.join('../raw_data/background/',file),'r',encoding='utf-8').readlines()\n",
    "        \n",
    "        sentence_count = 0\n",
    "        n1 = 0\n",
    "        n2 = 0\n",
    "        lines = \"\".join(text)\n",
    "        for c in lines:\n",
    "            n2 += 1\n",
    "            if c == ' ':\n",
    "                if lines[n2-2] in [',','.','?','%',';','-','+','&']: \n",
    "                    tag = annotation_dict.get((n1,n2-2),\"OTHER\")\n",
    "                    word = lines[n1:n2-2]\n",
    "                    #print ((n1,n2-2), word, tag)\n",
    "                else:\n",
    "                    tag = annotation_dict.get((n1,n2-1),\"OTHER\")\n",
    "                    word = lines[n1:n2-1]\n",
    "                if len(word) > 0 and word not in stops:\n",
    "                    documents.append(document)\n",
    "                    sentences.append(sentence_count)\n",
    "                    words.append(word.lower())\n",
    "                    poss.append(get_pos(word))\n",
    "                    n1s.append(n1)\n",
    "                    if lines[n2-2] in [',','.','?','%',';','-','+','&']:\n",
    "                        n2s.append(n2-2)\n",
    "                    else:\n",
    "                        n2s.append(n2-1)\n",
    "                    #print ((n1,n2-1), word, tag)\n",
    "                n1 = n2\n",
    "            if c == '\\n':\n",
    "                sentence_count += 1\n",
    "\n",
    "subtask1_test = pd.DataFrame()\n",
    "subtask1_test['document'] = documents\n",
    "subtask1_test['sentence'] = sentences\n",
    "subtask1_test['n1'] = n1s\n",
    "subtask1_test['n2'] = n2s\n",
    "subtask1_test['word'] = words\n",
    "subtask1_test['pos'] = poss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>sentence</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1139-76322016000300016-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>lactante</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1139-76322016000300016-2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1139-76322016000300016-2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>mes</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1139-76322016000300016-2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1139-76322016000300016-2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>días</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S1139-76322016000300016-2</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>antecedentes</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S1139-76322016000300016-2</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>56</td>\n",
       "      <td>interés</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S1139-76322016000300016-2</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>67</td>\n",
       "      <td>acude</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S1139-76322016000300016-2</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>urgencias</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S1139-76322016000300016-2</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>92</td>\n",
       "      <td>pediatría</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    document  sentence  n1  n2          word    tag    pos\n",
       "0  S1139-76322016000300016-2         0   0   8      lactante  OTHER    ADV\n",
       "1  S1139-76322016000300016-2         0  12  13             1  OTHER    NUM\n",
       "2  S1139-76322016000300016-2         0  14  17           mes  OTHER   NOUN\n",
       "3  S1139-76322016000300016-2         0  20  22            29  OTHER    NUM\n",
       "4  S1139-76322016000300016-2         0  23  27          días  OTHER   NOUN\n",
       "5  S1139-76322016000300016-2         0  33  45  antecedentes  OTHER   NOUN\n",
       "6  S1139-76322016000300016-2         0  49  56       interés  OTHER   NOUN\n",
       "7  S1139-76322016000300016-2         0  62  67         acude  OTHER   VERB\n",
       "8  S1139-76322016000300016-2         0  70  79     urgencias  OTHER  PROPN\n",
       "9  S1139-76322016000300016-2         0  83  92     pediatría  OTHER   VERB"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtask1_dev.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>sentence</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0004-06142008000100008-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>presentamos</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0004-06142008000100008-1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>caso</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0004-06142008000100008-1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>mujer</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004-06142008000100008-1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0004-06142008000100008-1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>años</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S0004-06142008000100008-1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>53</td>\n",
       "      <td>fumadora</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S0004-06142008000100008-1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>59</td>\n",
       "      <td>20</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S0004-06142008000100008-1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>75</td>\n",
       "      <td>cigarrillos/día</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S0004-06142008000100008-1</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>100</td>\n",
       "      <td>antecedentes</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S0004-06142008000100008-1</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>111</td>\n",
       "      <td>personales</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    document  sentence   n1   n2             word   pos\n",
       "0  S0004-06142008000100008-1         0    0   11      presentamos  VERB\n",
       "1  S0004-06142008000100008-1         0   15   19             caso  NOUN\n",
       "2  S0004-06142008000100008-1         0   27   32            mujer  NOUN\n",
       "3  S0004-06142008000100008-1         0   36   38               30   NUM\n",
       "4  S0004-06142008000100008-1         0   39   43             años  NOUN\n",
       "5  S0004-06142008000100008-1         0   45   53         fumadora   ADJ\n",
       "6  S0004-06142008000100008-1         0   57   59               20   NUM\n",
       "7  S0004-06142008000100008-1         0   60   75  cigarrillos/día  NOUN\n",
       "8  S0004-06142008000100008-1         0   88  100     antecedentes  NOUN\n",
       "9  S0004-06142008000100008-1         0  101  111       personales   ADJ"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtask1_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtask1_test.to_csv('../data/subtask1_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
