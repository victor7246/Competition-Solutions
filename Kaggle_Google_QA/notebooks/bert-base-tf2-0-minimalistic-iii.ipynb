{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgements\n",
    "\n",
    "Oiginal kernel: https://www.kaggle.com/akensert/bert-base-tf2-0-minimalistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import bert_tokenization as tokenization\n",
    "import tensorflow.keras.backend as K\n",
    "import gc\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from math import floor, ceil\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Read data and tokenizer\n",
    "\n",
    "Read tokenizer and data, as well as defining the maximum sequence length that will be used for the input to Bert (maximum is usually 512 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape = (6079, 41)\n",
      "test shape = (476, 11)\n",
      "\n",
      "output categories:\n",
      "\t ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n",
      "\n",
      "input categories:\n",
      "\t ['question_title', 'question_body', 'answer']\n"
     ]
    }
   ],
   "source": [
    "PATH = '../input/google-quest-challenge/'\n",
    "BERT_PATH = '../input/bert-base-from-tfhub/bert_en_uncased_L-12_H-768_A-12'\n",
    "tokenizer = tokenization.FullTokenizer(BERT_PATH+'/assets/vocab.txt', True)\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "\n",
    "df_train = pd.read_csv(PATH+'train.csv')\n",
    "df_test = pd.read_csv(PATH+'test.csv')\n",
    "df_sub = pd.read_csv(PATH+'sample_submission.csv')\n",
    "print('train shape =', df_train.shape)\n",
    "print('test shape =', df_test.shape)\n",
    "\n",
    "output_categories = list(df_train.columns[11:])\n",
    "input_categories = list(df_train.columns[[1,2,5]])\n",
    "print('\\noutput categories:\\n\\t', output_categories)\n",
    "print('\\ninput categories:\\n\\t', input_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>answer</th>\n",
       "      <th>url</th>\n",
       "      <th>subcategory_academia</th>\n",
       "      <th>subcategory_android</th>\n",
       "      <th>subcategory_anime</th>\n",
       "      <th>subcategory_apple</th>\n",
       "      <th>subcategory_askubuntu</th>\n",
       "      <th>subcategory_bicycles</th>\n",
       "      <th>...</th>\n",
       "      <th>subcategory_unix</th>\n",
       "      <th>subcategory_ux</th>\n",
       "      <th>subcategory_webapps</th>\n",
       "      <th>subcategory_webmasters</th>\n",
       "      <th>subcategory_wordpress</th>\n",
       "      <th>category_culture</th>\n",
       "      <th>category_life_arts</th>\n",
       "      <th>category_science</th>\n",
       "      <th>category_stackoverflow</th>\n",
       "      <th>category_technology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What am I losing when using extension tubes in...</td>\n",
       "      <td>After playing around with macro photography on...</td>\n",
       "      <td>I just got extension tubes, so here's the skin...</td>\n",
       "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the distinction between a city and a s...</td>\n",
       "      <td>I am trying to understand what kinds of places...</td>\n",
       "      <td>It might be helpful to look into the definitio...</td>\n",
       "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maximum protusion length for through-hole comp...</td>\n",
       "      <td>I'm working on a PCB that has through-hole com...</td>\n",
       "      <td>Do you even need grooves?  We make several pro...</td>\n",
       "      <td>http://electronics.stackexchange.com/questions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can an affidavit be used in Beit Din?</td>\n",
       "      <td>An affidavit, from what i understand, is basic...</td>\n",
       "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
       "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do you make a binary image in Photoshop?</td>\n",
       "      <td>I am trying to make a binary image. I want mor...</td>\n",
       "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
       "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      question_title  \\\n",
       "0  What am I losing when using extension tubes in...   \n",
       "1  What is the distinction between a city and a s...   \n",
       "2  Maximum protusion length for through-hole comp...   \n",
       "3              Can an affidavit be used in Beit Din?   \n",
       "4       How do you make a binary image in Photoshop?   \n",
       "\n",
       "                                       question_body  \\\n",
       "0  After playing around with macro photography on...   \n",
       "1  I am trying to understand what kinds of places...   \n",
       "2  I'm working on a PCB that has through-hole com...   \n",
       "3  An affidavit, from what i understand, is basic...   \n",
       "4  I am trying to make a binary image. I want mor...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  I just got extension tubes, so here's the skin...   \n",
       "1  It might be helpful to look into the definitio...   \n",
       "2  Do you even need grooves?  We make several pro...   \n",
       "3  Sending an \"affidavit\" it is a dispute between...   \n",
       "4  Check out Image Trace in Adobe Illustrator. \\n...   \n",
       "\n",
       "                                                 url  subcategory_academia  \\\n",
       "0  http://photo.stackexchange.com/questions/9169/...                     0   \n",
       "1  http://rpg.stackexchange.com/questions/47820/w...                     0   \n",
       "2  http://electronics.stackexchange.com/questions...                     0   \n",
       "3  http://judaism.stackexchange.com/questions/551...                     0   \n",
       "4  http://graphicdesign.stackexchange.com/questio...                     0   \n",
       "\n",
       "   subcategory_android  subcategory_anime  subcategory_apple  \\\n",
       "0                    0                  0                  0   \n",
       "1                    0                  0                  0   \n",
       "2                    0                  0                  0   \n",
       "3                    0                  0                  0   \n",
       "4                    0                  0                  0   \n",
       "\n",
       "   subcategory_askubuntu  subcategory_bicycles  ...  subcategory_unix  \\\n",
       "0                      0                     0  ...                 0   \n",
       "1                      0                     0  ...                 0   \n",
       "2                      0                     0  ...                 0   \n",
       "3                      0                     0  ...                 0   \n",
       "4                      0                     0  ...                 0   \n",
       "\n",
       "   subcategory_ux  subcategory_webapps  subcategory_webmasters  \\\n",
       "0               0                    0                       0   \n",
       "1               0                    0                       0   \n",
       "2               0                    0                       0   \n",
       "3               0                    0                       0   \n",
       "4               0                    0                       0   \n",
       "\n",
       "   subcategory_wordpress  category_culture  category_life_arts  \\\n",
       "0                      0                 0                   1   \n",
       "1                      0                 1                   0   \n",
       "2                      0                 0                   0   \n",
       "3                      0                 1                   0   \n",
       "4                      0                 0                   1   \n",
       "\n",
       "   category_science  category_stackoverflow  category_technology  \n",
       "0                 0                       0                    0  \n",
       "1                 0                       0                    0  \n",
       "2                 1                       0                    0  \n",
       "3                 0                       0                    0  \n",
       "4                 0                       0                    0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([df_train[['question_title','question_body','answer','url','category']],df_test[['question_title','question_body','answer','url','category']]],axis=0)\n",
    "\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "find = re.compile(r\"^[^.]*\")\n",
    "\n",
    "data['subcategory'] = data['url'].apply(lambda x: re.findall(find, urlparse(x.lower()).netloc)[0])\n",
    "data['category'] = data['category'].str.lower()\n",
    "data = pd.get_dummies(data, columns=['subcategory','category'])\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from scipy.stats import skew, kurtosis, spearmanr\n",
    "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
    "from nltk import word_tokenize\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['len_q1'] = data.question_title.apply(lambda x: len(str(x)))\n",
    "data['len_q2'] = data.question_body.apply(lambda x: len(str(x)))\n",
    "data['len_a'] = data.answer.apply(lambda x: len(str(x)))\n",
    "data['diff_len_q'] = data.len_q2 - data.len_q1\n",
    "data['diff_len_q_frac'] = data['diff_len_q']/data.len_q2\n",
    "\n",
    "data['diff_len_a1'] = data.len_a - data.len_q1\n",
    "data['diff_len_a2'] = data.len_a - data.len_q2\n",
    "data['diff_len_frac_a2'] = data['diff_len_a2']/data['len_a']\n",
    "\n",
    "data['len_word_q1'] = data.question_title.apply(lambda x: len(str(x).split()))\n",
    "data['len_word_q2'] = data.question_body.apply(lambda x: len(str(x).split()))\n",
    "data['len_word_frac_q2'] = data['len_word_q1']/data['len_word_q2']\n",
    "data['len_word_a'] = data.answer.apply(lambda x: len(str(x).split()))\n",
    "data['len_word_frac_a'] = data['len_word_q2']/data['len_word_a']\n",
    "\n",
    "data['common_words_q'] = data.apply(lambda x: len(set(str(x['question_title']).lower().split()).intersection(set(str(x['question_body']).lower().split()))), axis=1)\n",
    "data['common_words_frac_q'] = data['common_words_q']/data.len_word_q1\n",
    "data['common_words_frac2_q'] = data['common_words_q']/data.len_word_q2\n",
    "data['common_words_a1'] = data.apply(lambda x: len(set(str(x['question_title']).lower().split()).intersection(set(str(x['answer']).lower().split()))), axis=1)\n",
    "data['common_words_a2'] = data.apply(lambda x: len(set(str(x['answer']).lower().split()).intersection(set(str(x['question_body']).lower().split()))), axis=1)\n",
    "data['common_words_frac_a2'] = data['common_words_a2']/data['len_word_a']\n",
    "data['common_words_frac2_a2'] = data['common_words_a2']/data['len_word_q2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "st = PorterStemmer()\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "def clean(data):\n",
    "    tokens = tokenizer.tokenize(data.lower())\n",
    "    stop_free = \" \".join([st.stem(i) for i in tokens if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "data['clean_question_title'] = data.apply(lambda row :clean(row['question_title']),axis=1)\n",
    "data['clean_question_title'] = data.apply(lambda row: re.sub(r'\\d+', '',row['clean_question_title']),axis=1)\n",
    "\n",
    "data['clean_question_body'] = data.apply(lambda row :clean(row['question_body']),axis=1)\n",
    "data['clean_question_body'] = data.apply(lambda row: re.sub(r'\\d+', '',row['clean_question_body']),axis=1)\n",
    "\n",
    "data['clean_answer'] = data.apply(lambda row :clean(row['answer']),axis=1)\n",
    "data['clean_answer'] = data.apply(lambda row: re.sub(r'\\d+', '',row['clean_answer']),axis=1)\n",
    "\n",
    "data['question_title_wordlen'] = data.clean_question_title.apply(lambda x: len(x.split()))\n",
    "data['question_body_wordlen'] = data.clean_question_body.apply(lambda x: len(x.split()))\n",
    "data['answer_wordlen'] = data.clean_answer.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_question_words(x):\n",
    "    count = 0\n",
    "    count += x.count(\"?\")\n",
    "    for word in x.lower().split():\n",
    "        if word.startswith(\"wh\") or word.startswith(\"how\"):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def count_compare_words(x):\n",
    "    count = 0\n",
    "    count += x.lower().split().count(\"or\")\n",
    "    for word in x.lower().split():\n",
    "        if word.startswith(\"distinct\") or word.startswith(\"between\") or \"advantage\" in word or word.startswith(\"vs\") or word.startswith(\"differ\") :\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def count_consequence_words(x):\n",
    "    if x.startswith(\"if\") or x.startswith(\"is\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    return count\n",
    "\n",
    "data[\"q_count_title\"] = data.question_title.apply(count_question_words)\n",
    "data[\"q_count_body\"] = data.question_body.apply(count_question_words)\n",
    "\n",
    "data[\"compare_count_title\"] = data.question_title.apply(count_compare_words)\n",
    "data[\"compare_count_body\"] = data.question_body.apply(count_compare_words)\n",
    "\n",
    "data[\"consq_count_title\"] = data.question_title.apply(count_consequence_words)\n",
    "data[\"consq_count_body\"] = data.question_body.apply(count_consequence_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "import scipy\n",
    "\n",
    "lda1 = LatentDirichletAllocation(n_components=20)\n",
    "lda2 = LatentDirichletAllocation(n_components=20)\n",
    "\n",
    "cv1 = CountVectorizer(max_df=.7,min_df=5,max_features=50000)\n",
    "\n",
    "answer_vector = cv1.fit_transform(data.clean_answer)\n",
    "title_vector = cv1.transform(data.clean_question_title)\n",
    "body_vector = cv1.transform(data.clean_question_body)\n",
    "\n",
    "cv2 = CountVectorizer(max_df=.7,min_df=5,max_features=50000)\n",
    "\n",
    "body_vector2 = cv2.fit_transform(data.clean_question_body)\n",
    "answer_vector2 = cv2.transform(data.clean_answer)\n",
    "title_vector2 = cv2.transform(data.clean_question_title)\n",
    "\n",
    "answer_topics = lda1.fit_transform(answer_vector)\n",
    "title_topics = lda1.transform(title_vector)\n",
    "body_topics = lda1.transform(body_vector)\n",
    "\n",
    "body_topics2 = lda2.fit_transform(body_vector2)\n",
    "answer_topics2 = lda2.transform(answer_vector2)\n",
    "title_topics2 = lda2.transform(title_vector2)\n",
    "\n",
    "\n",
    "title_topic_entropy = scipy.stats.entropy(title_topics.T)\n",
    "body_topic_entropy = scipy.stats.entropy(body_topics.T)\n",
    "answer_topic_entropy = scipy.stats.entropy(answer_topics.T)\n",
    "\n",
    "title_topic_entropy2 = scipy.stats.entropy(title_topics2.T)\n",
    "body_topic_entropy2 = scipy.stats.entropy(body_topics2.T)\n",
    "answer_topic_entropy2 = scipy.stats.entropy(answer_topics2.T)\n",
    "\n",
    "#document_topic_entropy_len_normalized = document_topic_entropy * np.sqrt(word_len/2)\n",
    "def geometric_mean(x):\n",
    "    x = [i for i in x if i!=0]\n",
    "    if len(x) > 0:\n",
    "        return scipy.stats.mstats.gmean(x)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def popularity(matrix):\n",
    "    matrix = matrix.toarray()\n",
    "    idf_matrix = (matrix > 0).astype(int)\n",
    "    word_freq = idf_matrix.sum(axis=0)\n",
    "    idf_matrix = idf_matrix * word_freq\n",
    "    idf_matrix = idf_matrix * 1.0/idf_matrix.shape[0]\n",
    "\n",
    "    document_popularity = np.array([geometric_mean(x) for x in idf_matrix.tolist()])\n",
    "    return document_popularity\n",
    "\n",
    "title_popularity = popularity(title_vector)\n",
    "body_popularity = popularity(body_vector)\n",
    "answer_popularity = popularity(answer_vector)\n",
    "\n",
    "title_popularity2 = popularity(title_vector2)\n",
    "body_popularity2 = popularity(body_vector2)\n",
    "answer_popularity2 = popularity(answer_vector2)\n",
    "\n",
    "data['title_entropy'] = title_topic_entropy\n",
    "data['body_entropy'] = body_topic_entropy\n",
    "data['answer_entropy'] = answer_topic_entropy\n",
    "\n",
    "data['title_entropy2'] = title_topic_entropy2\n",
    "data['body_entropy2'] = body_topic_entropy2\n",
    "data['answer_entropy2'] = answer_topic_entropy2\n",
    "\n",
    "data['title_popularity'] = title_popularity\n",
    "data['body_popularity'] = body_popularity\n",
    "data['answer_popularity'] = answer_popularity\n",
    "\n",
    "data['title_popularity2'] = title_popularity2\n",
    "data['body_popularity2'] = body_popularity2\n",
    "data['answer_popularity2'] = answer_popularity2\n",
    "\n",
    "nmf1 = NMF(n_components=20)\n",
    "nmf2 = NMF(n_components=20)\n",
    "\n",
    "nmf_ans = nmf1.fit_transform(answer_vector)\n",
    "nmf_title = nmf1.transform(title_vector)\n",
    "nmf_body = nmf1.transform(body_vector)\n",
    "\n",
    "nmf_body2 = nmf2.fit_transform(body_vector2)\n",
    "nmf_title2 = nmf2.transform(title_vector2)\n",
    "nmf_ans2 = nmf2.transform(answer_vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_word_frac_q2\n",
      "common_words_frac2_q\n",
      "common_words_frac2_a2\n"
     ]
    }
   ],
   "source": [
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "for col in data:\n",
    "    if data[col].isna().any():\n",
    "        print (col)\n",
    "        if 'popularity' in col or 'frac' in col:\n",
    "            data[col] = data[col].fillna(0)\n",
    "        elif 'distance' in col:\n",
    "            data[col] = data[col].fillna(1)\n",
    "        else:\n",
    "            data[col] = data[col].fillna(-99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = list(data.columns)[5:]\n",
    "new_features.remove('clean_question_title')\n",
    "new_features.remove('clean_question_body')\n",
    "new_features.remove('clean_answer')\n",
    "\n",
    "for col in new_features:\n",
    "    if data[col].isna().any():\n",
    "        print (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6555, 344)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "new_X = np.hstack([mm.fit_transform(data[new_features]), nmf_ans, nmf_ans2, nmf_body, nmf_body2, nmf_title, nmf_body2, body_topics, body_topics2, title_topics, title_topics2, answer_topics, answer_topics2])\n",
    "print (new_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6079, 344) (476, 344)\n"
     ]
    }
   ],
   "source": [
    "train_Xnew = new_X[:df_train.shape[0]]\n",
    "test_Xnew = new_X[df_train.shape[0]:]\n",
    "\n",
    "print (train_Xnew.shape,test_Xnew.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Preprocessing functions\n",
    "\n",
    "These are some functions that will be used to preprocess the raw text data into useable Bert inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(BERT_PATH+'/assets/vocab.txt', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    first_sep = True\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            if first_sep:\n",
    "                first_sep = False \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def _trim_input(title, question, answer, max_sequence_length, \n",
    "                t_max_len=30, q_max_len=239, a_max_len=239):\n",
    "\n",
    "    t = tokenizer.tokenize(title)\n",
    "    q = tokenizer.tokenize(question)\n",
    "    a = tokenizer.tokenize(answer)\n",
    "    \n",
    "    t_len = len(t)\n",
    "    q_len = len(q)\n",
    "    a_len = len(a)\n",
    "\n",
    "    if (t_len+q_len+a_len+4) > max_sequence_length:\n",
    "        \n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "        if a_max_len > a_len:\n",
    "            a_new_len = a_len \n",
    "            q_new_len = q_max_len + (a_max_len - a_len)\n",
    "        elif q_max_len > q_len:\n",
    "            a_new_len = a_max_len + (q_max_len - q_len)\n",
    "            q_new_len = q_len\n",
    "        else:\n",
    "            a_new_len = a_max_len\n",
    "            q_new_len = q_max_len\n",
    "            \n",
    "            \n",
    "        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
    "        \n",
    "        t = t[:t_new_len]\n",
    "        q = q[:q_new_len]\n",
    "        a = a[:a_new_len]\n",
    "    \n",
    "    return t, q, a\n",
    "\n",
    "def _convert_to_bert_inputs(title, question, answer, tokenizer, max_sequence_length):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    \n",
    "    stoken = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "\n",
    "    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n",
    "    input_masks = _get_masks(stoken, max_sequence_length)\n",
    "    input_segments = _get_segments(stoken, max_sequence_length)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "def compute_input_arays(df, columns, tokenizer, max_sequence_length):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for _, instance in tqdm(df[columns].iterrows()):\n",
    "        t, q, a = instance.question_title, instance.question_body, instance.answer\n",
    "\n",
    "        t, q, a = _trim_input(t, q, a, max_sequence_length)\n",
    "\n",
    "        ids, masks, segments = _convert_to_bert_inputs(t, q, a, tokenizer, max_sequence_length)\n",
    "        input_ids.append(ids)\n",
    "        input_masks.append(masks)\n",
    "        input_segments.append(segments)\n",
    "        \n",
    "    return [np.asarray(input_ids, dtype=np.int32), \n",
    "            np.asarray(input_masks, dtype=np.int32), \n",
    "            np.asarray(input_segments, dtype=np.int32)]\n",
    "\n",
    "\n",
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create model\n",
    "\n",
    "`compute_spearmanr()` is used to compute the competition metric for the validation set\n",
    "<br><br>\n",
    "`CustomCallback()` is a class which inherits from `tf.keras.callbacks.Callback` and will compute and append validation score and validation/test predictions respectively, after each epoch.\n",
    "<br><br>\n",
    "`bert_model()` contains the actual architecture that will be used to finetune BERT to our dataset. It's simple, just taking the sequence_output of the bert_layer and pass it to an AveragePooling layer and finally to an output layer of 30 units (30 classes that we have to predict)\n",
    "<br><br>\n",
    "`train_and_predict()` this function will be run to train and obtain predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spearmanr(trues, preds):\n",
    "    rhos = []\n",
    "    for col_trues, col_pred in zip(trues.T, preds.T):\n",
    "        rhos.append(\n",
    "            spearmanr(col_trues, col_pred + np.random.normal(0, 1e-7, col_pred.shape[0])).correlation)\n",
    "    return np.mean(rhos)\n",
    "\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, valid_data, test_data, batch_size=16, fold=None):\n",
    "\n",
    "        self.valid_inputs = valid_data[0]\n",
    "        self.valid_outputs = valid_data[1]\n",
    "        self.test_inputs = test_data\n",
    "        self.best_value = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.fold = fold\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.valid_predictions = []\n",
    "        self.test_predictions = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.valid_predictions.append(\n",
    "            self.model.predict(self.valid_inputs, batch_size=self.batch_size))\n",
    "        \n",
    "        rho_val = compute_spearmanr(\n",
    "            self.valid_outputs, np.average(self.valid_predictions, axis=0))\n",
    "        \n",
    "        print(\"\\nvalidation rho: %.4f\" % rho_val)\n",
    "        \n",
    "        if rho_val > self.best_value:\n",
    "            self.best_value = rho_val\n",
    "            print (\"Model saved\")\n",
    "            self.model.save_weights('bert-base-{}.h5'.format(self.fold))\n",
    "        \n",
    "        self.test_predictions.append(\n",
    "            self.model.predict(self.test_inputs, batch_size=self.batch_size)\n",
    "        )\n",
    "\n",
    "def bert_model1():\n",
    "    \n",
    "    input_word_ids = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    input_segments = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_segments')\n",
    "    \n",
    "    input_additional_features = tf.keras.layers.Input(\n",
    "        (new_X.shape[1],), dtype=tf.float32, name='additional_features')\n",
    "    \n",
    "    bert_layer = hub.KerasLayer(BERT_PATH, trainable=True)\n",
    "    \n",
    "    _, sequence_output = bert_layer([input_word_ids, input_masks, input_segments])\n",
    "    \n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Concatenate(-1)([x,input_additional_features])\n",
    "    x = tf.keras.layers.Dense(100, activation=\"relu\", name=\"dense_features\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    out = tf.keras.layers.Dense(30, activation=\"sigmoid\", name=\"dense_output\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[input_word_ids, input_masks, input_segments, input_additional_features], outputs=out)\n",
    "    \n",
    "    return model \n",
    "\n",
    "def bert_model():\n",
    "    \n",
    "    input_word_ids = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    input_segments = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_segments')\n",
    "    \n",
    "    \n",
    "    bert_layer = hub.KerasLayer(BERT_PATH, trainable=True)\n",
    "    \n",
    "    _, sequence_output = bert_layer([input_word_ids, input_masks, input_segments])\n",
    "    \n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    out = tf.keras.layers.Dense(30, activation=\"sigmoid\", name=\"dense_output\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[input_word_ids, input_masks, input_segments], outputs=out)\n",
    "    \n",
    "    return model \n",
    "        \n",
    "def train_and_predict(model, train_data, valid_data, test_data, \n",
    "                      learning_rate, epochs, batch_size, loss_function, fold):\n",
    "        \n",
    "    custom_callback = CustomCallback(\n",
    "        valid_data=(valid_data[0], valid_data[1]), \n",
    "        test_data=test_data,\n",
    "        batch_size=batch_size,\n",
    "        fold=fold)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=loss_function, optimizer=optimizer)\n",
    "    model.fit(train_data[0], train_data[1], epochs=epochs, \n",
    "              batch_size=batch_size, callbacks=[custom_callback])\n",
    "    \n",
    "    return custom_callback\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Obtain inputs and targets, as well as the indices of the train/validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92c339976024248a58132a5d8a0327e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26493c4d82234ca79f07170366a070d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = compute_output_arrays(df_train, output_categories)\n",
    "inputs = compute_input_arays(df_train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "test_inputs = compute_input_arays(df_test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "new_test_inputs = test_inputs + [test_Xnew]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Training, validation and testing\n",
    "\n",
    "Loops over the folds in gkf and trains each fold for 5 epochs --- with a learning rate of 1e-5 and batch_size of 8. A simple binary crossentropy is used as the objective-/loss-function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_segments (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 input_segments[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 768)          0           keras_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 768)          0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_output (Dense)            (None, 30)           23070       dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 109,505,311\n",
      "Trainable params: 109,505,310\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = bert_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.2        0.26666667 0.3        0.33333333 0.33333333\n",
      " 0.4        0.44444444 0.46666667 0.5        0.53333333 0.55555556\n",
      " 0.6        0.66666667 0.66666667 0.7        0.73333333 0.77777778\n",
      " 0.8        0.83333333 0.86666667 0.88888889 0.9        0.93333333\n",
      " 1.        ]\n"
     ]
    }
   ],
   "source": [
    "uniq_numbers = np.unique(df_train[output_categories].values.flatten())\n",
    "print (uniq_numbers)\n",
    "\n",
    "def rounder(values):\n",
    "    def f(x):\n",
    "        idx = np.argmin(np.abs(values - x))\n",
    "        return values[idx]\n",
    "    return np.frompyfunc(f, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def abs_KL_div(y_true, y_pred):\n",
    "    y_true = K.clip(y_true, K.epsilon(), None)\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), None)\n",
    "    return K.sum( K.abs( (y_true- y_pred) * (K.log(y_true / y_pred))), axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_bce(y_true, y_pred):\n",
    "    y_true = K.clip(y_true, K.epsilon(), None)\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), None)\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5471 samples\n",
      "Epoch 1/5\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 0.3948\n",
      "validation rho: 0.3500\n",
      "Model saved\n",
      "5471/5471 [==============================] - 411s 75ms/sample - loss: 0.3949\n",
      "Epoch 2/5\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 0.3653\n",
      "validation rho: 0.3687\n",
      "Model saved\n",
      "5471/5471 [==============================] - 380s 69ms/sample - loss: 0.3653\n",
      "Epoch 3/5\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 0.3480\n",
      "validation rho: 0.3788\n",
      "Model saved\n",
      "5471/5471 [==============================] - 380s 69ms/sample - loss: 0.3480\n",
      "Epoch 4/5\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 0.3277\n",
      "validation rho: 0.3787\n",
      "5471/5471 [==============================] - 379s 69ms/sample - loss: 0.3278\n",
      "Epoch 5/5\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 0.3061\n",
      "validation rho: 0.3768\n",
      "5471/5471 [==============================] - 379s 69ms/sample - loss: 0.3060\n",
      "Train on 5471 samples\n",
      "Epoch 1/5\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 0.3949\n",
      "validation rho: 0.3547\n",
      "Model saved\n",
      "5471/5471 [==============================] - 410s 75ms/sample - loss: 0.3949\n",
      "Epoch 2/5\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 0.3649\n",
      "validation rho: 0.3800\n",
      "Model saved\n",
      "5471/5471 [==============================] - 380s 69ms/sample - loss: 0.3650\n",
      "Epoch 3/5\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 0.3475\n",
      "validation rho: 0.3870\n",
      "Model saved\n",
      "5471/5471 [==============================] - 380s 69ms/sample - loss: 0.3475\n",
      "Epoch 4/5\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 0.3275\n",
      "validation rho: 0.3906\n",
      "Model saved\n",
      "5471/5471 [==============================] - 380s 69ms/sample - loss: 0.3275\n",
      "Epoch 5/5\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 0.3049\n",
      "validation rho: 0.3924\n",
      "Model saved\n",
      "5471/5471 [==============================] - 380s 69ms/sample - loss: 0.3049\n",
      "Train on 5471 samples\n",
      "Epoch 1/5\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 0.3975\n",
      "validation rho: 0.3769\n",
      "Model saved\n",
      "5471/5471 [==============================] - 408s 75ms/sample - loss: 0.3975\n",
      "Epoch 2/5\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 0.3659\n",
      "validation rho: 0.3944\n",
      "Model saved\n",
      "5471/5471 [==============================] - 379s 69ms/sample - loss: 0.3659\n",
      "Epoch 3/5\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 0.3478\n",
      "validation rho: 0.4025\n",
      "Model saved\n",
      "5471/5471 [==============================] - 379s 69ms/sample - loss: 0.3478\n",
      "Epoch 4/5\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 0.3287\n",
      "validation rho: 0.4027\n",
      "Model saved\n",
      "5471/5471 [==============================] - 379s 69ms/sample - loss: 0.3287\n",
      "Epoch 5/5\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 0.3080\n",
      "validation rho: 0.4027\n",
      "Model saved\n",
      "5471/5471 [==============================] - 380s 69ms/sample - loss: 0.3080\n"
     ]
    }
   ],
   "source": [
    "gkf = GroupKFold(n_splits=10).split(X=df_train.question_body, groups=df_train.question_body) ############## originaln_splits=5\n",
    "\n",
    "histories = []\n",
    "for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
    "    \n",
    "    # will actually only do 3 folds (out of 5) to manage < 2h\n",
    "    if fold in [5,6,7]:\n",
    "        K.clear_session()\n",
    "        model = bert_model()\n",
    "        \n",
    "        train_inputs = [inputs[i][train_idx] for i in range(3)] #+ [train_Xnew[train_idx]]\n",
    "        train_outputs = outputs[train_idx]\n",
    "\n",
    "        valid_inputs = [inputs[i][valid_idx] for i in range(3)] #+ [train_Xnew[valid_idx]]\n",
    "        valid_outputs = outputs[valid_idx]\n",
    "\n",
    "        # history contains two lists of valid and test preds respectively:\n",
    "        #  [valid_predictions_{fold}, test_predictions_{fold}]\n",
    "        history = train_and_predict(model, \n",
    "                          train_data=(train_inputs, train_outputs), \n",
    "                          valid_data=(valid_inputs, valid_outputs),\n",
    "                          test_data=test_inputs, \n",
    "                          learning_rate=3e-5, epochs=5, batch_size=8,\n",
    "                          loss_function=noisy_bce, fold=fold) #binary_crossentropy\n",
    "\n",
    "        model.load_weights('bert-base-{}.h5'.format(fold))\n",
    "        val_pred = model.predict(valid_inputs)\n",
    "        rounded_val_pred = np.array([rounder(uniq_numbers)(i) for i in val_pred])\n",
    "        \n",
    "        histories.append(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Process and submit test predictions\n",
    "\n",
    "First the test predictions are read from the list of lists of `histories`. Then each test prediction list (in lists) is averaged. Then a mean of the averages is computed to get a single prediction for each data point. Finally, this is saved to `submission.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred2 = [histories[i].valid_predictions for i in range(len(histories))]\n",
    "val_pred2 = [np.average(val_pred2[i], axis=0) for i in range(len(val_pred2))]\n",
    "val_pred2 = np.mean(val_pred2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_asker_intent_understanding oof spearman correlation 0.28238634651862016 , 0.2828239288696029 and 0.2551552540128391\n",
      "question_body_critical oof spearman correlation 0.4965524775465909 , 0.4934486408373993 and 0.4970766545598862\n",
      "question_conversational oof spearman correlation 0.40706743145466057 , 0.42206197149912067 and 0.4492477828361911\n",
      "question_expect_short_answer oof spearman correlation 0.2754949071461538 , 0.2618787016338228 and 0.273281604711095\n",
      "question_fact_seeking oof spearman correlation 0.3511553336139033 , 0.33544343988248837 and 0.3494184905160427\n",
      "question_has_commonly_accepted_answer oof spearman correlation 0.4513086343581561 , 0.5268123153884202 and 0.4759619221317155\n",
      "question_interestingness_others oof spearman correlation 0.2176276607299437 , 0.21574494063098856 and 0.20341272064425284\n",
      "question_interestingness_self oof spearman correlation 0.4991028536014139 , 0.4909406483385501 and 0.500384807845734\n",
      "question_multi_intent oof spearman correlation 0.522495960701336 , 0.5237718779113425 and 0.5176637125865955\n",
      "question_not_really_a_question oof spearman correlation 0.13812778221751126 , 0.13812778221751126 and 0.13812778221751126\n",
      "question_opinion_seeking oof spearman correlation 0.4513240279759352 , 0.4498456881240945 and 0.44594494246945876\n",
      "question_type_choice oof spearman correlation 0.6854634452773298 , 0.6946571585756308 and 0.6916618257748692\n",
      "question_type_compare oof spearman correlation 0.39333587354093924 , 0.49138651621066837 and 0.5337616300784398\n",
      "question_type_consequence oof spearman correlation 0.15728789598082332 , -0.0070889427146159905 and -0.010033547202583707\n",
      "question_type_definition oof spearman correlation 0.3807446016640704 , 0.5752464517348327 and 0.6218573495889428\n",
      "question_type_entity oof spearman correlation 0.43273957550049036 , 0.4006235445832665 and 0.4247798928443786\n",
      "question_type_instructions oof spearman correlation 0.754277990907454 , 0.7585318485894281 and 0.7546766745196855\n",
      "question_type_procedure oof spearman correlation 0.3392762837430889 , 0.3008872706593339 and 0.3151427944870872\n",
      "question_type_reason_explanation oof spearman correlation 0.6494947422867583 , 0.6413850818600341 and 0.6499720814821263\n",
      "question_type_spelling oof spearman correlation 0.07018624157119589 , 0.07018624157119589 and 0.07018624157119589\n",
      "question_well_written oof spearman correlation 0.41933134847877146 , 0.41663905841910764 and 0.4107325769540198\n",
      "answer_helpful oof spearman correlation 0.1985407982753933 , 0.18187543846022852 and 0.18425963238699103\n",
      "answer_level_of_information oof spearman correlation 0.32244809593209656 , 0.31286558571520934 and 0.3198871905079164\n",
      "answer_plausible oof spearman correlation 0.09326709078667757 , 0.04125777395785973 and 0.1044730319688648\n",
      "answer_relevance oof spearman correlation 0.20298915382158128 , 0.1007956704760264 and 0.2057261598623142\n",
      "answer_satisfaction oof spearman correlation 0.3107760125642806 , 0.31194185534148594 and 0.3078863012954624\n",
      "answer_type_instructions oof spearman correlation 0.726676671570232 , 0.7192356696602439 and 0.725842368821993\n",
      "answer_type_procedure oof spearman correlation 0.28828838086820635 , 0.2227405565733563 and 0.23992510245504364\n",
      "answer_type_reason_explanation oof spearman correlation 0.6467969361814128 , 0.6253285941827694 and 0.6463835010557689\n",
      "answer_well_written oof spearman correlation 0.15363901634759228 , 0.1415417909423543 and 0.1408664284731149\n",
      "overall scores 0.3772734523720873, 0.3713645700043919 and 0.3814554303818986\n"
     ]
    }
   ],
   "source": [
    "uniq_numbers_per_class = [np.unique(df_train[output_categories].values[:,i]) for i in range(len(output_categories))]\n",
    "                                    \n",
    "rounded_val_pred = np.array([rounder(uniq_numbers_per_class[i])(val_pred[:,i]) for i in range(len(output_categories))]).T\n",
    "rounded_val_pred2 = np.array([rounder(uniq_numbers)(i) for i in val_pred])\n",
    "\n",
    "for i in range(len(output_categories)):\n",
    "    if len(np.unique(rounded_val_pred[:,i])) == 1:\n",
    "        rounded_val_pred[:,i] = val_pred[:,i].copy()\n",
    "        \n",
    "for i in range(len(output_categories)):\n",
    "    if len(np.unique(rounded_val_pred2[:,i])) == 1:\n",
    "        rounded_val_pred2[:,i] = val_pred[:,i].copy()\n",
    "        \n",
    "score1 = 0\n",
    "score2 = 0\n",
    "score3 = 0\n",
    "\n",
    "for col_ind, col in enumerate(output_categories):\n",
    "    score1 += spearmanr(valid_outputs[:,col_ind],val_pred[:,col_ind]).correlation\n",
    "    score2 += spearmanr(valid_outputs[:,col_ind],rounded_val_pred[:,col_ind]).correlation\n",
    "    score3 += spearmanr(valid_outputs[:,col_ind],rounded_val_pred2[:,col_ind]).correlation\n",
    "    print (\"{} oof spearman correlation {} , {} and {}\".format(col, spearmanr(valid_outputs[:,col_ind],val_pred[:,col_ind]).correlation, spearmanr(valid_outputs[:,col_ind],rounded_val_pred[:,col_ind]).correlation, spearmanr(valid_outputs[:,col_ind],rounded_val_pred2[:,col_ind]).correlation))\n",
    "\n",
    "print (\"overall scores {}, {} and {}\".format(score1/30, score2/30, score3/30))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_asker_intent_understanding oof spearman correlation 0.28238634651862016 , 0.15356777903665791 and 0.2085662773424169\n",
      "question_body_critical oof spearman correlation 0.4965524775465909 , 0.2833624161715703 and 0.2822657729492392\n",
      "question_conversational oof spearman correlation 0.40706743145466057 , 0.12818692811443738 and 0.23374002138877956\n",
      "question_expect_short_answer oof spearman correlation 0.2754949071461538 , 0.10777937696187478 and 0.10984585635748093\n",
      "question_fact_seeking oof spearman correlation 0.3511553336139033 , 0.18628374694985492 and 0.2691750472515131\n",
      "question_has_commonly_accepted_answer oof spearman correlation 0.4513086343581561 , 0.2929005133155003 and 0.3057651661543264\n",
      "question_interestingness_others oof spearman correlation 0.2176276607299437 , 0.13751429350993563 and 0.15391894997653444\n",
      "question_interestingness_self oof spearman correlation 0.4991028536014139 , 0.2914183656099262 and 0.30067074190993565\n",
      "question_multi_intent oof spearman correlation 0.522495960701336 , 0.3555337233828054 and 0.4266667748109069\n",
      "question_not_really_a_question oof spearman correlation 0.13812778221751126 , 0.09513310549825185 and 0.09513310549825185\n",
      "question_opinion_seeking oof spearman correlation 0.4513240279759352 , 0.28572867025849924 and 0.2713994764436617\n",
      "question_type_choice oof spearman correlation 0.6854634452773298 , 0.37465190896333933 and 0.38473678304586245\n",
      "question_type_compare oof spearman correlation 0.39333587354093924 , 0.3268864984881185 and 0.3655185226960163\n",
      "question_type_consequence oof spearman correlation 0.15728789598082332 , 0.16714716751045633 and 0.16714716751045633\n",
      "question_type_definition oof spearman correlation 0.3807446016640704 , 0.0201867301098466 and 0.19903290411686692\n",
      "question_type_entity oof spearman correlation 0.43273957550049036 , 0.06417070418266994 and 0.14906843124815095\n",
      "question_type_instructions oof spearman correlation 0.754277990907454 , 0.4452959127862664 and 0.4669244423796926\n",
      "question_type_procedure oof spearman correlation 0.3392762837430889 , 0.15681152903833848 and 0.14993299820840583\n",
      "question_type_reason_explanation oof spearman correlation 0.6494947422867583 , 0.35313206221281657 and 0.3475958712982796\n",
      "question_type_spelling oof spearman correlation 0.07018624157119589 , 0.0699549844872942 and 0.0699549844872942\n",
      "question_well_written oof spearman correlation 0.41933134847877146 , 0.2417633093918885 and 0.24395576316084813\n",
      "answer_helpful oof spearman correlation 0.1985407982753933 , 0.0554066271455855 and 0.10574738802049916\n",
      "answer_level_of_information oof spearman correlation 0.32244809593209656 , 0.15340177301621327 and 0.21239478868623565\n",
      "answer_plausible oof spearman correlation 0.09326709078667757 , 0.012906078203787016 and 0.07326548507185145\n",
      "answer_relevance oof spearman correlation 0.20298915382158128 , 0.010103182752416631 and 0.06058596014069072\n",
      "answer_satisfaction oof spearman correlation 0.3107760125642806 , 0.16933249857269367 and 0.1691680237692592\n",
      "answer_type_instructions oof spearman correlation 0.726676671570232 , 0.44056748194081596 and 0.4529666359783872\n",
      "answer_type_procedure oof spearman correlation 0.28828838086820635 , 0.11777504342357013 and 0.12329519512949846\n",
      "answer_type_reason_explanation oof spearman correlation 0.6467969361814128 , 0.3648182257354986 and 0.3832527168333264\n",
      "answer_well_written oof spearman correlation 0.15363901634759228 , -0.017541092746212048 and 0.07933449489923773\n",
      "overall scores 0.23976722352021262, 0.19480598480082395 and 0.22870085822546354\n"
     ]
    }
   ],
   "source": [
    "uniq_numbers_per_class = [np.unique(df_train[output_categories].values[:,i]) for i in range(len(output_categories))]\n",
    "                                    \n",
    "rounded_val_pred = np.array([rounder(uniq_numbers_per_class[i])(val_pred2[:,i]) for i in range(len(output_categories))]).T\n",
    "rounded_val_pred2 = np.array([rounder(uniq_numbers)(i) for i in val_pred2])\n",
    "\n",
    "for i in range(len(output_categories)):\n",
    "    if len(np.unique(rounded_val_pred[:,i])) == 1:\n",
    "        rounded_val_pred[:,i] = val_pred2[:,i].copy()\n",
    "        \n",
    "for i in range(len(output_categories)):\n",
    "    if len(np.unique(rounded_val_pred2[:,i])) == 1:\n",
    "        rounded_val_pred2[:,i] = val_pred2[:,i].copy()\n",
    "        \n",
    "score1 = 0\n",
    "score2 = 0\n",
    "score3 = 0\n",
    "\n",
    "for col_ind, col in enumerate(output_categories):\n",
    "    score1 += spearmanr(valid_outputs[:,col_ind],val_pred2[:,col_ind]).correlation\n",
    "    score2 += spearmanr(valid_outputs[:,col_ind],rounded_val_pred[:,col_ind]).correlation\n",
    "    score3 += spearmanr(valid_outputs[:,col_ind],rounded_val_pred2[:,col_ind]).correlation\n",
    "    print (\"{} oof spearman correlation {} , {} and {}\".format(col, spearmanr(valid_outputs[:,col_ind],val_pred[:,col_ind]).correlation, spearmanr(valid_outputs[:,col_ind],rounded_val_pred[:,col_ind]).correlation, spearmanr(valid_outputs[:,col_ind],rounded_val_pred2[:,col_ind]).correlation))\n",
    "\n",
    "print (\"overall scores {}, {} and {}\".format(score1/30, score2/30, score3/30))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = [histories[i].test_predictions for i in range(len(histories))]\n",
    "test_predictions = [np.average(test_predictions[i], axis=0) for i in range(len(test_predictions))]\n",
    "test_predictions = np.mean(test_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_test_predictions = np.array([rounder(uniq_numbers)(i) for i in test_predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476, 30)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 418.8222222222225\n",
      "1 274.5777777777774\n",
      "2 7.766666666666669\n",
      "3 337.6888888888886\n",
      "4 389.93333333333356\n",
      "5 406.5444444444448\n",
      "6 278.2999999999984\n",
      "7 233.91111111111167\n",
      "8 106.85555555555571\n",
      "9 0.0\n",
      "10 183.46666666666704\n",
      "11 129.05555555555551\n",
      "12 7.077777777777779\n",
      "13 1.7999999999999998\n",
      "14 5.933333333333334\n",
      "15 11.966666666666665\n",
      "16 251.44444444444437\n",
      "17 80.56666666666693\n",
      "18 188.6888888888888\n",
      "19 0.0\n",
      "20 372.34444444444466\n",
      "21 439.53333333333416\n",
      "22 317.5222222222216\n",
      "23 455.53333333333427\n",
      "24 468.2000000000004\n",
      "25 411.65555555555596\n",
      "26 251.4555555555554\n",
      "27 70.53333333333372\n",
      "28 244.28888888888872\n",
      "29 432.1555555555558\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print (i, rounded_test_predictions[:,i].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 418.8222222222225\n",
      "1 274.5777777777774\n",
      "2 7.766666666666669\n",
      "3 337.6888888888886\n",
      "4 389.93333333333356\n",
      "5 406.5444444444448\n",
      "6 278.2999999999984\n",
      "7 233.91111111111167\n",
      "8 106.85555555555571\n",
      "9 3.609214697731659\n",
      "10 183.46666666666704\n",
      "11 129.05555555555551\n",
      "12 7.077777777777779\n",
      "13 1.7999999999999998\n",
      "14 5.933333333333334\n",
      "15 11.966666666666665\n",
      "16 251.44444444444437\n",
      "17 80.56666666666693\n",
      "18 188.6888888888888\n",
      "19 1.4992365323705599\n",
      "20 372.34444444444466\n",
      "21 439.53333333333416\n",
      "22 317.5222222222216\n",
      "23 455.53333333333427\n",
      "24 468.2000000000004\n",
      "25 411.65555555555596\n",
      "26 251.4555555555554\n",
      "27 70.53333333333372\n",
      "28 244.28888888888872\n",
      "29 432.1555555555558\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(output_categories):\n",
    "    if len(np.unique(rounded_test_predictions[:,i])) == 1:  #or col in ['question_not_really_a_question','question_type_consequence','answer_helpful','answer_plausible','answer_relevance','answer_well_written']:\n",
    "        rounded_test_predictions[:,i] = test_predictions[:,i].copy()\n",
    "        \n",
    "    print (i, rounded_test_predictions[:,i].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.iloc[:, 1:] = rounded_test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <th>question_type_choice</th>\n",
       "      <th>question_type_compare</th>\n",
       "      <th>question_type_consequence</th>\n",
       "      <th>question_type_definition</th>\n",
       "      <th>question_type_entity</th>\n",
       "      <th>question_type_instructions</th>\n",
       "      <th>question_type_procedure</th>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <th>question_type_spelling</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.002477</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011945</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010255</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.933333                0.666667   \n",
       "1     46                             0.888889                0.533333   \n",
       "2     70                             0.900000                0.600000   \n",
       "3    132                             0.866667                0.444444   \n",
       "4    200                             0.933333                0.444444   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                      0.2                      0.466667   \n",
       "1                      0.0                      0.800000   \n",
       "2                      0.0                      0.777778   \n",
       "3                      0.0                      0.733333   \n",
       "4                      0.0                      0.800000   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.600000                               0.600000   \n",
       "1               0.777778                               0.933333   \n",
       "2               0.866667                               0.933333   \n",
       "3               0.733333                               0.933333   \n",
       "4               0.733333                               0.800000   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.666667                       0.666667   \n",
       "1                         0.555556                       0.444444   \n",
       "2                         0.600000                       0.466667   \n",
       "3                         0.555556                       0.444444   \n",
       "4                         0.666667                       0.600000   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  \\\n",
       "0                    0.6                        0.008313   \n",
       "1                    0.0                        0.005243   \n",
       "2                    0.2                        0.005132   \n",
       "3                    0.0                        0.011945   \n",
       "4                    0.0                        0.010255   \n",
       "\n",
       "   question_opinion_seeking  question_type_choice  question_type_compare  \\\n",
       "0                  0.700000              0.700000                    0.0   \n",
       "1                  0.400000              0.444444                    0.0   \n",
       "2                  0.300000              0.666667                    0.0   \n",
       "3                  0.533333              0.000000                    0.0   \n",
       "4                  0.500000              0.200000                    0.0   \n",
       "\n",
       "   question_type_consequence  question_type_definition  question_type_entity  \\\n",
       "0                        0.2                       0.0                   0.0   \n",
       "1                        0.0                       0.0                   0.0   \n",
       "2                        0.0                       0.0                   0.0   \n",
       "3                        0.0                       0.0                   0.0   \n",
       "4                        0.0                       0.0                   0.0   \n",
       "\n",
       "   question_type_instructions  question_type_procedure  \\\n",
       "0                    0.200000                      0.0   \n",
       "1                    0.866667                      0.2   \n",
       "2                    0.200000                      0.0   \n",
       "3                    0.833333                      0.2   \n",
       "4                    0.266667                      0.2   \n",
       "\n",
       "   question_type_reason_explanation  question_type_spelling  \\\n",
       "0                          0.800000                0.004053   \n",
       "1                          0.000000                0.001750   \n",
       "2                          0.700000                0.002477   \n",
       "3                          0.533333                0.002448   \n",
       "4                          0.500000                0.002517   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.900000        0.888889                     0.600000   \n",
       "1               0.700000        0.933333                     0.666667   \n",
       "2               0.833333        0.933333                     0.600000   \n",
       "3               0.666667        0.933333                     0.666667   \n",
       "4               0.700000        0.900000                     0.666667   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.933333          0.933333             0.777778   \n",
       "1          1.000000          1.000000             0.900000   \n",
       "2          0.933333          1.000000             0.833333   \n",
       "3          1.000000          1.000000             0.900000   \n",
       "4          0.933333          0.933333             0.833333   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.000000                    0.0   \n",
       "1                  0.933333                    0.2   \n",
       "2                  0.200000                    0.0   \n",
       "3                  0.866667                    0.2   \n",
       "4                  0.200000                    0.2   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.833333             0.933333  \n",
       "1                        0.000000             0.900000  \n",
       "2                        0.833333             0.900000  \n",
       "3                        0.500000             0.888889  \n",
       "4                        0.666667             0.900000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <th>question_type_choice</th>\n",
       "      <th>question_type_compare</th>\n",
       "      <th>question_type_consequence</th>\n",
       "      <th>question_type_definition</th>\n",
       "      <th>question_type_entity</th>\n",
       "      <th>question_type_instructions</th>\n",
       "      <th>question_type_procedure</th>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <th>question_type_spelling</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5029.186975</td>\n",
       "      <td>0.879879</td>\n",
       "      <td>0.576844</td>\n",
       "      <td>0.016317</td>\n",
       "      <td>0.709430</td>\n",
       "      <td>0.819188</td>\n",
       "      <td>0.854085</td>\n",
       "      <td>0.584664</td>\n",
       "      <td>0.491410</td>\n",
       "      <td>0.224486</td>\n",
       "      <td>0.007582</td>\n",
       "      <td>0.385434</td>\n",
       "      <td>0.271125</td>\n",
       "      <td>0.014869</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>0.012465</td>\n",
       "      <td>0.025140</td>\n",
       "      <td>0.528245</td>\n",
       "      <td>0.169258</td>\n",
       "      <td>0.396405</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.782236</td>\n",
       "      <td>0.923389</td>\n",
       "      <td>0.667063</td>\n",
       "      <td>0.957003</td>\n",
       "      <td>0.983613</td>\n",
       "      <td>0.864823</td>\n",
       "      <td>0.528268</td>\n",
       "      <td>0.148179</td>\n",
       "      <td>0.513212</td>\n",
       "      <td>0.907890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2812.670060</td>\n",
       "      <td>0.047424</td>\n",
       "      <td>0.128354</td>\n",
       "      <td>0.061463</td>\n",
       "      <td>0.111886</td>\n",
       "      <td>0.092230</td>\n",
       "      <td>0.118733</td>\n",
       "      <td>0.050854</td>\n",
       "      <td>0.084471</td>\n",
       "      <td>0.205989</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>0.162842</td>\n",
       "      <td>0.302404</td>\n",
       "      <td>0.077476</td>\n",
       "      <td>0.030199</td>\n",
       "      <td>0.066164</td>\n",
       "      <td>0.092803</td>\n",
       "      <td>0.338325</td>\n",
       "      <td>0.102713</td>\n",
       "      <td>0.275100</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.089065</td>\n",
       "      <td>0.023109</td>\n",
       "      <td>0.046987</td>\n",
       "      <td>0.031935</td>\n",
       "      <td>0.028734</td>\n",
       "      <td>0.038993</td>\n",
       "      <td>0.328970</td>\n",
       "      <td>0.096483</td>\n",
       "      <td>0.283256</td>\n",
       "      <td>0.022081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2572.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005407</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5093.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7482.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9640.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.025891</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011654</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             qa_id  question_asker_intent_understanding  \\\n",
       "count   476.000000                           476.000000   \n",
       "mean   5029.186975                             0.879879   \n",
       "std    2812.670060                             0.047424   \n",
       "min      39.000000                             0.733333   \n",
       "25%    2572.000000                             0.833333   \n",
       "50%    5093.000000                             0.888889   \n",
       "75%    7482.000000                             0.933333   \n",
       "max    9640.000000                             1.000000   \n",
       "\n",
       "       question_body_critical  question_conversational  \\\n",
       "count              476.000000               476.000000   \n",
       "mean                 0.576844                 0.016317   \n",
       "std                  0.128354                 0.061463   \n",
       "min                  0.333333                 0.000000   \n",
       "25%                  0.466667                 0.000000   \n",
       "50%                  0.555556                 0.000000   \n",
       "75%                  0.666667                 0.000000   \n",
       "max                  0.888889                 0.533333   \n",
       "\n",
       "       question_expect_short_answer  question_fact_seeking  \\\n",
       "count                    476.000000             476.000000   \n",
       "mean                       0.709430               0.819188   \n",
       "std                        0.111886               0.092230   \n",
       "min                        0.266667               0.333333   \n",
       "25%                        0.666667               0.777778   \n",
       "50%                        0.700000               0.833333   \n",
       "75%                        0.777778               0.888889   \n",
       "max                        0.933333               1.000000   \n",
       "\n",
       "       question_has_commonly_accepted_answer  question_interestingness_others  \\\n",
       "count                             476.000000                       476.000000   \n",
       "mean                                0.854085                         0.584664   \n",
       "std                                 0.118733                         0.050854   \n",
       "min                                 0.300000                         0.500000   \n",
       "25%                                 0.833333                         0.555556   \n",
       "50%                                 0.900000                         0.555556   \n",
       "75%                                 0.933333                         0.600000   \n",
       "max                                 1.000000                         0.733333   \n",
       "\n",
       "       question_interestingness_self  question_multi_intent  \\\n",
       "count                     476.000000             476.000000   \n",
       "mean                        0.491410               0.224486   \n",
       "std                         0.084471               0.205989   \n",
       "min                         0.333333               0.000000   \n",
       "25%                         0.444444               0.000000   \n",
       "50%                         0.466667               0.200000   \n",
       "75%                         0.533333               0.333333   \n",
       "max                         0.777778               0.800000   \n",
       "\n",
       "       question_not_really_a_question  question_opinion_seeking  \\\n",
       "count                      476.000000                476.000000   \n",
       "mean                         0.007582                  0.385434   \n",
       "std                          0.003374                  0.162842   \n",
       "min                          0.002687                  0.000000   \n",
       "25%                          0.005407                  0.266667   \n",
       "50%                          0.006726                  0.400000   \n",
       "75%                          0.008982                  0.500000   \n",
       "max                          0.025891                  0.866667   \n",
       "\n",
       "       question_type_choice  question_type_compare  question_type_consequence  \\\n",
       "count            476.000000             476.000000                 476.000000   \n",
       "mean               0.271125               0.014869                   0.003782   \n",
       "std                0.302404               0.077476                   0.030199   \n",
       "min                0.000000               0.000000                   0.000000   \n",
       "25%                0.000000               0.000000                   0.000000   \n",
       "50%                0.200000               0.000000                   0.000000   \n",
       "75%                0.500000               0.000000                   0.000000   \n",
       "max                0.933333               0.666667                   0.400000   \n",
       "\n",
       "       question_type_definition  question_type_entity  \\\n",
       "count                476.000000            476.000000   \n",
       "mean                   0.012465              0.025140   \n",
       "std                    0.066164              0.092803   \n",
       "min                    0.000000              0.000000   \n",
       "25%                    0.000000              0.000000   \n",
       "50%                    0.000000              0.000000   \n",
       "75%                    0.000000              0.000000   \n",
       "max                    0.733333              0.666667   \n",
       "\n",
       "       question_type_instructions  question_type_procedure  \\\n",
       "count                  476.000000               476.000000   \n",
       "mean                     0.528245                 0.169258   \n",
       "std                      0.338325                 0.102713   \n",
       "min                      0.000000                 0.000000   \n",
       "25%                      0.200000                 0.200000   \n",
       "50%                      0.666667                 0.200000   \n",
       "75%                      0.833333                 0.200000   \n",
       "max                      0.933333                 0.400000   \n",
       "\n",
       "       question_type_reason_explanation  question_type_spelling  \\\n",
       "count                        476.000000              476.000000   \n",
       "mean                           0.396405                0.003150   \n",
       "std                            0.275100                0.001169   \n",
       "min                            0.000000                0.001585   \n",
       "25%                            0.200000                0.002395   \n",
       "50%                            0.333333                0.002814   \n",
       "75%                            0.600000                0.003530   \n",
       "max                            1.000000                0.011654   \n",
       "\n",
       "       question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "count             476.000000      476.000000                   476.000000   \n",
       "mean                0.782236        0.923389                     0.667063   \n",
       "std                 0.089065        0.023109                     0.046987   \n",
       "min                 0.555556        0.833333                     0.533333   \n",
       "25%                 0.700000        0.900000                     0.666667   \n",
       "50%                 0.777778        0.933333                     0.666667   \n",
       "75%                 0.866667        0.933333                     0.700000   \n",
       "max                 0.933333        1.000000                     0.833333   \n",
       "\n",
       "       answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "count        476.000000        476.000000           476.000000   \n",
       "mean           0.957003          0.983613             0.864823   \n",
       "std            0.031935          0.028734             0.038993   \n",
       "min            0.933333          0.933333             0.733333   \n",
       "25%            0.933333          1.000000             0.833333   \n",
       "50%            0.933333          1.000000             0.866667   \n",
       "75%            1.000000          1.000000             0.888889   \n",
       "max            1.000000          1.000000             0.933333   \n",
       "\n",
       "       answer_type_instructions  answer_type_procedure  \\\n",
       "count                476.000000             476.000000   \n",
       "mean                   0.528268               0.148179   \n",
       "std                    0.328970               0.096483   \n",
       "min                    0.000000               0.000000   \n",
       "25%                    0.200000               0.000000   \n",
       "50%                    0.666667               0.200000   \n",
       "75%                    0.833333               0.200000   \n",
       "max                    0.933333               0.333333   \n",
       "\n",
       "       answer_type_reason_explanation  answer_well_written  \n",
       "count                      476.000000           476.000000  \n",
       "mean                         0.513212             0.907890  \n",
       "std                          0.283256             0.022081  \n",
       "min                          0.000000             0.833333  \n",
       "25%                          0.266667             0.900000  \n",
       "50%                          0.533333             0.900000  \n",
       "75%                          0.777778             0.933333  \n",
       "max                          1.000000             0.933333  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0123596338b44a1188c5a44bf1309f5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "26493c4d82234ca79f07170366a070d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_32fe7f00b1d24218af7c87a8bf3ca615",
        "IPY_MODEL_73064033a49543f0b61e02b15a7aa32b"
       ],
       "layout": "IPY_MODEL_778c373af74c403f82b25d116d1e5410"
      }
     },
     "32fe7f00b1d24218af7c87a8bf3ca615": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_57576628e86c4712afc1bd82ed1f664c",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dd543bbaa2a1473283ae38d5f2518633",
       "value": 1
      }
     },
     "57576628e86c4712afc1bd82ed1f664c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "64066ede60234cfea8935cbce8f84757": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6cdf77a57dc14b93bd31377a05e2e01b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "73064033a49543f0b61e02b15a7aa32b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ca0c8ab9563f46308078fc96419fb2e2",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_d1da18da744747a1bee3c7807be1ce71",
       "value": " 476/? [00:06&lt;00:00, 69.17it/s]"
      }
     },
     "778c373af74c403f82b25d116d1e5410": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ad0ee98f5d64031b25626b6432ea2a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0123596338b44a1188c5a44bf1309f5c",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_932fa68fffd14c57a990f1514e907ee5",
       "value": 1
      }
     },
     "8e59fe5c6249461c9009f3472a9dfd6e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_64066ede60234cfea8935cbce8f84757",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_e4dfc4505d3344e6865b9de6819725d5",
       "value": " 6079/? [01:17&lt;00:00, 78.48it/s]"
      }
     },
     "932fa68fffd14c57a990f1514e907ee5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "b92c339976024248a58132a5d8a0327e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8ad0ee98f5d64031b25626b6432ea2a1",
        "IPY_MODEL_8e59fe5c6249461c9009f3472a9dfd6e"
       ],
       "layout": "IPY_MODEL_6cdf77a57dc14b93bd31377a05e2e01b"
      }
     },
     "ca0c8ab9563f46308078fc96419fb2e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d1da18da744747a1bee3c7807be1ce71": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "dd543bbaa2a1473283ae38d5f2518633": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "e4dfc4505d3344e6865b9de6819725d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
